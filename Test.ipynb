{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from urllib import request\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout,Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "file_path='data'\n",
    "\n",
    "\n",
    "import splitfolders\n",
    "splitted_folder='./splitted_folder'\n",
    "def train_test_valid(train_size=0.6,test_size=0.2,val_size=0.2,images_folder=file_path,splitted_folder=splitted_folder):\n",
    "  train_size = train_size\n",
    "  test_size = test_size\n",
    "  val_size = val_size\n",
    "  input_folder = images_folder\n",
    "  output_folder = splitted_folder\n",
    "  splitfolders.ratio(input_folder,output_folder, seed = 1337, ratio = (train_size,test_size,val_size), group_prefix = None)\n",
    "train_test_valid()\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_file_path = './splitted_folder/train'\n",
    "test_file_path =  './splitted_folder/test'\n",
    "val_file_path =  './splitted_folder/val'\n",
    "\n",
    "def data_pre_processing(valid_split = 0,input_size = (260, 260),image_color = 'rgb',batch_size = 32,\n",
    "                        shuffle=True):\n",
    "\n",
    "\n",
    "    train_gen=ImageDataGenerator(rescale=1/255.0,validation_split=valid_split,fill_mode='nearest',rotation_range=40,horizontal_flip=True)\n",
    "\n",
    "    validation_gen=ImageDataGenerator(rescale=1/255.0,validation_split=valid_split)\n",
    "\n",
    "    test_gen=ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "    train_data=train_gen.flow_from_directory(directory=train_file_path,target_size=input_size,color_mode=image_color,\n",
    "                                             batch_size=batch_size,shuffle=shuffle,class_mode='categorical')\n",
    "    test_data=test_gen.flow_from_directory(directory=test_file_path,target_size=input_size,color_mode=image_color,\n",
    "                                             batch_size=batch_size,shuffle=shuffle,class_mode='categorical')\n",
    "    valid_data=validation_gen.flow_from_directory(directory=val_file_path,target_size=input_size,color_mode=image_color,\n",
    "                                             batch_size=batch_size,shuffle=shuffle,class_mode='categorical')\n",
    "\n",
    "    return train_data,test_data,valid_data\n",
    "\n",
    "train,test,validation=data_pre_processing()\n",
    "\n",
    "\n",
    "\n",
    "values_counter=Counter(train.classes)\n",
    "sorted(values_counter.items())\n",
    "plt.bar(train.class_indices.keys(), values_counter.values(), color=(1, 0.1, 0.1, 0.6))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "labels=dict()\n",
    "for label_name,label_num in train.class_indices.items():\n",
    "        labels[label_num]=label_name\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in tqdm(range(9)):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    for x_batch,y_batch in train:\n",
    "        image=x_batch[0]\n",
    "        argmax=np.argmax(y_batch)\n",
    "        plt.tight_layout(h_pad=5)\n",
    "        plt.title(labels[argmax])\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "import efficientnet.tfkeras as enet\n",
    "def configure_model():\n",
    "  inputs_1 = tf.keras.Input(shape=(260, 260, 3))\n",
    "  mymodel=enet.EfficientNetB2(input_shape = (260, 260, 3), include_top = False, weights = 'imagenet')\n",
    "  x = tf.keras.layers.AveragePooling2D(pool_size=(7, 7))(mymodel.output)\n",
    "  x = tf.keras.layers.Flatten()(x)\n",
    "  predictors = tf.keras.layers.Dense(4,activation='softmax',name='Predictions')(x)\n",
    "  final_model = Model(mymodel.input, outputs=predictors)\n",
    "  return final_model\n",
    "final_model=configure_model()\n",
    "def model(new_model=final_model,layers_num=1,trainable=False):\n",
    "    for layer in new_model.layers[:layers_num]:\n",
    "        layer.trainable=trainable\n",
    "    return new_model\n",
    "final_model=model(final_model)\n",
    "def scheduler(epoch, lr):\n",
    "  if epoch < 3:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(0.0001)\n",
    "final_model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "def callbacks(patience=2):\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint('my_model.weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    early=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=patience,min_delta=0.001)\n",
    "    lr=tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    callbacks_list=[checkpoint, early,lr]\n",
    "    return callbacks_list\n",
    "\n",
    "callbacks=callbacks()\n",
    "counter = Counter(train.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights1 = {class_id : max_val/num_images for class_id, num_images in counter.items()}   \n",
    "\n",
    "\n",
    "hist=final_model.fit(train,\n",
    "                     epochs=3,\n",
    "                     validation_data=(validation),\n",
    "                     callbacks=callbacks,\n",
    "                     class_weight=class_weights1)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"accuracy\",\"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"loss\",\"Validation Loss\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_real=[]\n",
    "all_pred=[]\n",
    "count=0\n",
    "for x,y in test:\n",
    "  predict=final_model.predict(x)\n",
    "  \n",
    "  for i in predict:\n",
    "    all_pred.append(np.argmax(i)+1)\n",
    "  for i in y:\n",
    "    i=np.argmax(i)+1\n",
    "    y_real.append(i)\n",
    "\n",
    "  if len(y_real)==len(test.filepaths):\n",
    "    break\n",
    "\n",
    "target_names =[]\n",
    "for key,value in test.class_indices.items():\n",
    "  target_names.append(f'condition: {key}')\n",
    "\n",
    "from sklearn import metrics\n",
    "report=metrics.classification_report(y_real,all_pred,target_names=target_names)\n",
    "conf_efficnet2=metrics.confusion_matrix(y_real,all_pred)\n",
    "\n",
    "\n",
    "import itertools\n",
    "def plot_confusion_matrix(cnf_matrix, numbers_type='numbers_and_percentage', class_names=target_names, title='Confusion matrix', cmap=plt.cm.Blues, file_name='confusionmatrix.png'):\n",
    "    combined = True\n",
    "    cnf_matrix_normalized = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    thresh = 0.8*cnf_matrix.max() / 1.\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        if numbers_type == 'numbers_and_percentage':\n",
    "            st1 = '{:.2f}%'.format(100 * cnf_matrix_normalized[i, j])\n",
    "            st2 = '({:2d})'.format(cnf_matrix[i, j])\n",
    "            plt.text(j, i, st1+st2,\n",
    "                     horizontalalignment=\"center\", verticalalignment='bottom',\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        elif numbers_type == 'percentage':\n",
    "            fmt = '.2f'\n",
    "            plt.text(j, i, format(cnf_matrix_normalized[i, j], fmt),\n",
    "                     horizontalalignment=\"center\", verticalalignment='bottom',\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            fmt = 'd'\n",
    "            plt.text(j, i, format(cnf_matrix[i, j], fmt),\n",
    "                     horizontalalignment=\"center\", verticalalignment='bottom',\n",
    "                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(file_name)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "plot_confusion_matrix(conf_efficnet2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
