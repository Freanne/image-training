{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:20:20,683 - INFO - Importing required libraries.\n",
      "2024-10-09 15:20:30,361 - INFO - Creating artefacts directory if it doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info(\"Importing required libraries.\")\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow import data as tf_data\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "# from sklearn.utils import class_weight\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "\n",
    "\n",
    "logging.info(\"Creating artefacts directory if it doesn't exist.\")\n",
    "os.makedirs(\"artefacts\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"graphs\", exist_ok=True)\n",
    "image_size = ( 260 , 260 )\n",
    "batch_size = 64\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:21:44,130 - INFO - Loading dataset from directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4188 files belonging to 4 classes.\n",
      "Using 3141 files for training.\n",
      "Using 1047 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:21:44,609 - INFO - Setting up data augmentation layers.\n",
      "2024-10-09 15:21:44,620 - INFO - Applying data augmentation to training dataset.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Loading dataset from directory.\")\n",
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    \"data\",\n",
    "    validation_split=0.25,\n",
    "    subset=\"both\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "logging.info(\"Setting up data augmentation layers.\")\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomRotation(factor=0.15),\n",
    "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "    layers.RandomFlip(),\n",
    "    layers.RandomContrast(factor=0.1)\n",
    "]\n",
    "\n",
    "def data_augmentation(images):\n",
    "    for layer in data_augmentation_layers :\n",
    "        images = layer(images)\n",
    "    return images\n",
    "\n",
    "logging.info(\"Applying data augmentation to training dataset.\")\n",
    "def apply_data_augmentation(img, label):\n",
    "    return data_augmentation(img), label\n",
    "\n",
    "#logging.info(\"Applying data augmentation to training dataset.\")\n",
    "train_ds = train_ds.map(apply_data_augmentation, num_parallel_calls=tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 15:22:04,271 - INFO - Prefetching training and validation datasets.\n",
      "2024-10-09 15:22:04,293 - INFO - Number of images in training dataset: 3200\n",
      "2024-10-09 15:22:04,294 - INFO - Number of images in validation dataset: 1088\n",
      "2024-10-09 15:22:04,294 - INFO - Counting the number of images per class in the training dataset.\n",
      "2024-10-09 15:22:18.543146: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-10-09 15:22:18,577 - INFO - Number of images per class in the training dataset: {2: 434, 3: 864, 1: 979, 0: 864}\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Prefetching training and validation datasets.\")\n",
    "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf_data.AUTOTUNE)\n",
    "\n",
    "train_size = tf_data.experimental.cardinality(train_ds).numpy()\n",
    "val_size = tf_data.experimental.cardinality(val_ds).numpy()\n",
    "\n",
    "logging.info(f\"Number of images in training dataset: {train_size * batch_size}\")\n",
    "logging.info(f\"Number of images in validation dataset: {val_size * batch_size}\")\n",
    "\n",
    "logging.info(\"Counting the number of images per class in the training dataset.\")\n",
    "class_counts = {}\n",
    "for _, labels in train_ds.unbatch():\n",
    "    class_idx = labels.numpy()\n",
    "    if class_idx in class_counts:\n",
    "        class_counts[class_idx] += 1\n",
    "    else:\n",
    "        class_counts[class_idx] = 1\n",
    "\n",
    "logging.info(f\"Number of images per class in the training dataset: {class_counts}\")\n",
    "\n",
    "total_images = sum(class_counts.values())\n",
    "class_weights = {class_idx: total_images / (len(class_counts) * count) for class_idx, count in class_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model_0(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 0 - EfficientNetB0.\")\n",
    "    model = EfficientNetB0(\n",
    "        include_top=True,\n",
    "        weights=None,\n",
    "        classes=num_classes,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "def create_model_0_1(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 0_1 - EfficientNetB0 with pretrained weights.\")\n",
    "    inputs = layers.Input(shape=input_shape)  # Input layer\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    logging.info(\"Freezing the pretrained weights.\")\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    logging.info(\"Rebuilding the top layers.\")\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    logging.info(\"Compiling the model.\")\n",
    "    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def create_model_1(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 1.\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        units = 1\n",
    "    else:\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    # We specify activation=None so as to return logits\n",
    "    outputs = layers.Dense(units, activation=None)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "    \n",
    "\n",
    "def create_model_2(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 2 - Inception-Like Model.\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "\n",
    "    # First block\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Inception-like block\n",
    "    tower_1 = layers.Conv2D(64, 1, padding=\"same\", activation=\"relu\")(x)\n",
    "    tower_1 = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(tower_1)\n",
    "    \n",
    "    tower_2 = layers.Conv2D(64, 1, padding=\"same\", activation=\"relu\")(x)\n",
    "    tower_2 = layers.Conv2D(128, 5, padding=\"same\", activation=\"relu\")(tower_2)\n",
    "    \n",
    "    tower_3 = layers.MaxPooling2D(3, strides=1, padding=\"same\")(x)\n",
    "    tower_3 = layers.Conv2D(128, 1, padding=\"same\", activation=\"relu\")(tower_3)\n",
    "\n",
    "    x = layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Additional blocks\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def create_model_3(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 3 - ResNet-Like Model.\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
    "        residual = layers.BatchNormalization()(residual)  # Ensure batch normalization is applied to the residual\n",
    "\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        units = 1\n",
    "    else:\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    outputs = layers.Dense(units, activation=None)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def create_model_4(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 4 - LeNet-5.\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(6, kernel_size=5, activation='relu')(x)\n",
    "    x = layers.AveragePooling2D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Conv2D(16, kernel_size=5, activation='relu')(x)\n",
    "    x = layers.AveragePooling2D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(120, activation='relu')(x)\n",
    "    x = layers.Dense(84, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "def create_model_5(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 5 - VGG-16 (light).\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "def create_model_6(input_shape, num_classes):\n",
    "    logging.info(\"Building Model 6 - MobileNetV2 (light).\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(32, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, kernel_size=1, padding='same', activation='relu')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, kernel_size=1, padding='same', activation='relu')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(128, kernel_size=1, padding='same', activation='relu')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=1, padding='same', activation='relu')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=1, padding='same', activation='relu')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(512, kernel_size=1, padding='same', activation='relu')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [create_model_0, create_model_0_1, create_model_1, create_model_2, create_model_3, create_model_4, create_model_5, create_model_6]\n",
    "\n",
    "for i, model_fn in enumerate(models):\n",
    "    logging.info(f\"Creating Model {i+1}.\")\n",
    "    model = model_fn(input_shape=image_size + (3,), num_classes=4)\n",
    "\n",
    "    logging.info(f\"Compiling Model {i+1}.\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(3e-4),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f\"models/best_model_{i+1}.keras\", save_best_only=True, monitor=\"val_acc\", mode=\"max\"\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True),\n",
    "        keras.callbacks.CSVLogger(f'artefacts/training_log_{i+1}.csv')  # Save training log\n",
    "    ]\n",
    "\n",
    "    logging.info(f\"Starting Model {i+1} training.\")\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_ds,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Plotting the learning curve for Model {i+1}.\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(history.history['acc'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Learning Curve - Model {i+1}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.savefig(f'artefacts/learning_curve_{i+1}.png')\n",
    "    plt.savefig(f'graphs/learning_curve_{i+1}.png')\n",
    "    plt.close()\n",
    "\n",
    "    logging.info(f\"Making predictions on the validation dataset for Model {i+1}.\")\n",
    "    val_predictions = model.predict(val_ds)\n",
    "    val_pred_labels = tf.argmax(val_predictions, axis=1)\n",
    "\n",
    "    logging.info(f\"Getting true labels from the validation dataset for Model {i+1}.\")\n",
    "    val_true_labels = tf.concat([y for _, y in val_ds], axis=0)\n",
    "\n",
    "    logging.info(f\"Computing the confusion matrix for Model {i+1}.\")\n",
    "    val_cm = confusion_matrix(val_true_labels, val_pred_labels)\n",
    "\n",
    "    logging.info(f\"Plotting the confusion matrix for Model {i+1}.\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    class_labels = sorted(set(val_true_labels.numpy()))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=val_cm, display_labels=class_labels)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=plt.gca())\n",
    "    plt.title(f'Confusion Matrix - Validation Set - Model {i+1}')\n",
    "    plt.savefig(f'artefacts/confusion_matrix_{i+1}.png')\n",
    "    plt.savefig(f'graphs/confusion_matrix_{i+1}.png')\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    logging.info(f\"Saving model weights for Model {i+1}.\")\n",
    "    model.save_weights(f'models/model_weights_{i+1}.weights.h5')\n",
    "    #model.save_weights(f'models/model_{i+1}.weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.info(\"Creating a zip archive of the artefacts directory.\")\n",
    "shutil.make_archive('artefacts', 'zip', 'artefacts')\n",
    "shutil.make_archive('models', 'zip', 'models')\n",
    "shutil.make_archive('graphs', 'zip', 'graphs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
